{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on TikTok Video Comments\n",
    "\n",
    "## Introduction\n",
    "This notebook details the steps taken to perform sentiment analysis on comments from TikTok videos using Python. The goal is to identify trends and patterns in sentiment across different video characteristics.\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "Ensure Python and the necessary libraries are installed. We will be using the following libraries:\n",
    "- `pandas` for data manipulation\n",
    "- `matplotlib` and `seaborn` for visualization\n",
    "- `VADER` from `nltk` for sentiment analysis\n",
    "- `scikit-learn` for building the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas nltk matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Your Dataset\n",
    "\n",
    "Import the necessary libraries and load the dataset using pandas. We focus on columns relevant to our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"tiktok_dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "\n",
    "### Histograms for Numeric Features\n",
    "\n",
    "Visualize the distribution of numeric variables such as video duration, view count, like count, etc. These insights can help identify any data cleaning needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric columns\n",
    "numeric_columns = ['video_duration_sec', 'video_view_count', 'video_like_count', 'video_share_count', 'video_download_count', 'video_comment_count']\n",
    "\n",
    "# Plotting histograms\n",
    "fig, ax = plt.subplots(len(numeric_columns), 1, figsize=(8, 20))\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    ax[i].hist(df[col].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "    ax[i].set_title(f'Distribution of {col}', fontsize=12)\n",
    "    ax[i].set_xlabel(col)\n",
    "    ax[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots to Identify Outliers\n",
    "\n",
    "Box plots for each numeric variable to visualize potential outliers, informing further data cleaning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting box plots\n",
    "fig, ax = plt.subplots(len(numeric_columns), 1, figsize=(8, 20))\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.boxplot(x=df[col], ax=ax[i])\n",
    "    ax[i].set_title(f'Box Plot of {col}', fontsize=12)\n",
    "    ax[i].set_xlabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Plots for Categorical Variables\n",
    "\n",
    "Visualize the distribution of categorical variables such as `verified_status` and `author_ban_status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting count plots for categorical columns\n",
    "categorical_columns = ['verified_status', 'author_ban_status']\n",
    "\n",
    "fig, ax = plt.subplots(len(categorical_columns), 1, figsize=(8, 10))\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    sns.countplot(x=df[col], ax=ax[i], palette='viridis', hue=df[col])\n",
    "    ax[i].set_title(f'Count of {col}', fontsize=12)\n",
    "    ax[i].set_xlabel(col)\n",
    "    ax[i].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Ensure data types are appropriate, handle missing values, and remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing and incorrect values\n",
    "df.update(df[numeric_columns].fillna(0))\n",
    "df[categorical_columns] = df[categorical_columns].fillna('Unknown')\n",
    "\n",
    "# Convert numerical fields to integers\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Remove duplicate entries\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Ensure all entries are strings. Convert NaNs to a default string and ensure all inputs are treated as strings.\n",
    "df['video_transcription_text'] = df['video_transcription_text'].fillna('No transcription available').astype(str)\n",
    "\n",
    "# Display cleaned data stats\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Sentiment Analysis\n",
    "\n",
    "Set up and apply the VADER sentiment analysis tool from nltk to the transcription text of the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/estifanos/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            video_transcription_text  sentiment_score  \\\n",
      "0  someone shared with me that drone deliveries a...           0.3400   \n",
      "1  someone shared with me that there are more mic...           0.3818   \n",
      "2  someone shared with me that american industria...           0.6369   \n",
      "3  someone shared with me that the metro of st. p...           0.3400   \n",
      "4  someone shared with me that the number of busi...           0.4019   \n",
      "\n",
      "  sentiment_category  \n",
      "0           positive  \n",
      "1           positive  \n",
      "2           positive  \n",
      "3           positive  \n",
      "4           positive  \n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Ensure all entries are strings and handle NaN before applying sentiment analysis\n",
    "df['video_transcription_text'] = df['video_transcription_text'].fillna('No transcription available').astype(str)\n",
    "\n",
    "# Applying sentiment analysis\n",
    "df['sentiment_score'] = df['video_transcription_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "df['sentiment_category'] = df['sentiment_score'].apply(lambda x: 'positive' if x > 0.05 else 'negative' if x < -0.05 else 'neutral')\n",
    "\n",
    "# Now you can safely proceed without encountering the AttributeError\n",
    "print(df[['video_transcription_text', 'sentiment_score', 'sentiment_category']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling: Sentiment Category Prediction\n",
    "\n",
    "Here we implement a Random Forest Classifier to predict the sentiment category based on video features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Selecting features and target variable\n",
    "features = df[['video_view_count', 'video_like_count', 'video_share_count', 'video_download_count', 'video_comment_count']]\n",
    "target = df['sentiment_category']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initializing the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Accuracy of the model: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Sentiment Distribution\n",
    "\n",
    "### Sentiment Distribution per Verification Status\n",
    "\n",
    "Visualize how sentiment distribution varies between verified and unverified videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='sentiment_category', hue='verified_status', data=df)\n",
    "plt.title('Sentiment Distribution by Verification Status')\n",
    "plt.xlabel('Sentiment Category')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Verified Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Video Metrics by Sentiment Category\n",
    "\n",
    "Average Video Metrics by Sentiment Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Metrics plots\n",
    "metrics = ['video_view_count', 'video_like_count', 'video_share_count', 'video_download_count']\n",
    "titles = ['Average Views', 'Average Likes', 'Average Shares', 'Average Downloads']\n",
    "for i, (ax, metric) in enumerate(zip(axes.flatten(), metrics)):\n",
    "    sns.barplot(ax=ax, x='sentiment_category', y=metric, data=df)\n",
    "    ax.set_title(titles[i] + ' by Sentiment')\n",
    "    ax.set_xlabel('Sentiment Category')\n",
    "    ax.set_ylabel('Average ' + metric.split('_')[1].capitalize())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
